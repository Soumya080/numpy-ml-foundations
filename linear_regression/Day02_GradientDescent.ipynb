{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjH6vzmi7oRpQc0JDG5ppc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Soumya080/numpy-ml-foundations/blob/main/linear_regression/Day02_GradientDescent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOOP LOGIC / TRAINING LOGIC\n",
        "1. PREDICT Y^\n",
        "2. COMPUTE LOSS\n",
        "3. COMPUTE GRADIENTS\n",
        "4. UPDATE W AND B\n",
        "5. CHECK LOSS"
      ],
      "metadata": {
        "id": "iNhPoF_Pwq9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# creating the dataset\n",
        "x = np.random.randn(100,1)\n",
        "y = 2.5*x + 0.2*np.random.randn(100,1)\n",
        "\n",
        "# initializing parameters\n",
        "w = np.random.randn(1,1)\n",
        "b = np.random.randn(1,1)\n",
        "\n",
        "lr = 0.01\n",
        "\n",
        "# training loop\n",
        "for i in range(100):  # 100 iterations\n",
        "    y_pred = x@w + b\n",
        "    loss = np.mean((y_pred - y)**2)\n",
        "\n",
        "    grad_w = np.mean(2*x*(y_pred - y))\n",
        "    grad_b = np.mean(2*(y_pred - y))\n",
        "\n",
        "    w -= lr * grad_w\n",
        "    b -= lr * grad_b\n",
        "\n",
        "    if i % 10 == 0:\n",
        "        print(f\"Iteration {i+10}: loss = {loss}\")\n",
        "\n",
        "print(\"Final weights:\", w, \"Final bias:\", b)\n",
        "print(\"Final loss:\", loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fweVMObjvs8C",
        "outputId": "de639de3-d82f-468b-dfd5-35b8bb49c395"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 10: loss = 1.9832417605048318\n",
            "Iteration 20: loss = 1.3108674026775833\n",
            "Iteration 30: loss = 0.8715208527526092\n",
            "Iteration 40: loss = 0.5843689012382992\n",
            "Iteration 50: loss = 0.3966420372509792\n",
            "Iteration 60: loss = 0.2738831975758326\n",
            "Iteration 70: loss = 0.19358748051888208\n",
            "Iteration 80: loss = 0.14105271899995453\n",
            "Iteration 90: loss = 0.10667180573985659\n",
            "Iteration 100: loss = 0.08416542049919665\n",
            "Final weights: [[2.31357971]] Final bias: [[0.02015706]]\n",
            "Final loss: 0.07063746659241439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SmyEnpjb0S5O"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ojqm0tdp18j3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}